<!DOCTYPE html>
<html lang="en" dir="ltr" itemscope itemtype="http://schema.org/WebPage">

<head>
    <link rel="icon" href="favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" sizes="180x180" href="./apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./favicon-16x16.png">
    <link rel="manifest" href="./site.webmanifest">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="Content-Type-Script" content="text/javascript">
    <meta name="Content-Type-Style" content="text/css">
    <meta name="author" content="Computer Vision And Image Understanding Lab">
    <meta name="description" content="Computer Vision And Image Understanding Lab">
    <link href="./assets/css/vendors/vendors.css" rel="stylesheet" type="text/css">
    <link href="./assets/css/vendors/vendors-overwrites.css" rel="stylesheet" type="text/css">
    <link href="./assets/css/styles.css" rel="stylesheet" type="text/css">
    <link href="./assets/css/demo1.css" rel="stylesheet" type="text/css">
    <script src="./assets/js/vendors/jquery.min.js"></script>
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700|Play:300,400|Source+Code+Pro:300,400"
        rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Sintony:400,700&amp;subset=latin,greek,cyrillic"
        rel="stylesheet" type="text/css">
    <title>Contact</title>
</head>

<body class="fullwidth sticky-header">
    <div id="wrapper" class="regular-layout">
        <header id="header" class="trans dark sticky-dark">
            <div class="head-main">
                <div class="container">
                    <div class="logo-wrapper"><a href="http://csce.uark.edu/"><img src="./assets/img/UA_Logo.png"
                                alt="UArk Logo" class="logo-light ol-retina"><img src="./assets/img/UA_Logo.png"
                                alt="UArk Logo" class="logo-dark ol-retina"></a></div>
                    <div class="text-logo" style="font-size: 20pt;"><b style="font-size: 25pt;">C</b>omputer <b
                            style="font-size: 25pt;">V</b>ision and <b style="font-size: 25pt;">I</b>mage <b
                            style="font-size: 25pt;">U</b>nderstanding Lab</div>
                    <ul id="primary-menu">
                        <li><a href="./index.html" title="Home"><span>Home</span></a></li>
                        <li><a href="./publication.html" title="Publication"><span>Publication</span></a></li>
                        <li><a href="https://github.com/uark-cviu" title="Data & Code"><span>Data & Code</span></a></li>
                        <li class="current-menu-item"><a href="./news.html"
                            title="News"><span>News</span></a></li>
                        <li><a href="./people.html" title="People"><span>People</span></a></li>
                        <li><a href="./contact.html" title="Contact"><span>Contact</span></a></li>
                    </ul>
                    <div class="header-icons">
                        <div class="ol-mobile-trigger hamburger hamburger--elastic">
                            <div class="hamburger-box">
                                <div class="hamburger-inner"></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <section id="contents">
            <div class="head-wrapper">
                <div data-parallax-mode="mode-title" class="page-head hvh-30 parallax-layer">
                    <section data-img-src="./assets/img/bg/oldmain.jpg" data-parallax-mode="mode-3"
                        class="section parallax-layer ov-dark-alpha-80 owl-videobg owl-video-wrapper"></section>
                </div>
            </div>
            <section class="page-contents">
                <section id="main-area">
                    <div class="shadow"></div>
                    <section class="section bg-white section-narrow-2">
                        <div class="container">
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="https://uark-cviu.github.io/projects/insect-foundation/imgs/insect_attention.gif" alt="Insect Foundation Model">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Insect Foundation Model</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">Insect-related disasters are one of the most important factors affecting crop yield due to the fast reproduction and widely distributed, large variety of insects. In the agricultural revolution, detecting and recognizing insects plays an important role in the ability for crops to grow healthily and produce a high-quality yield. To achieve this, insect recognition helps to differentiate between bugs that must be targeted for pest control and bugs that are essential for protecting farms. Machine learning, especially deep learning requires a large volume of data to achieve high performance. Therefore, we introduce a novel "Insect Foundation" dataset, a game-changing resource poised to revolutionize insect-related foundation model training. This rich and expansive dataset consists of 900,000 images with dense labels of taxonomy hierarchy from the high level of taxonomy (e.g., Class, Order) to the low level of taxonomy (e.g., Genus, Species). Covering a vast spectrum of insect species, our dataset offers a panoramic view of entomology, enabling foundation models to comprehend visual and semantic information about insects like never before. Our proposed dataset carries immense value, fostering breakthroughs across precision agriculture and entomology research. Insect Foundation Dataset promises to empower the next generation of insect-related AI models, bringing them closer to the ultimate goal of precision agriculture.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://uark-cviu.github.io/projects/insect-foundation/insect_foundation.html"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="https://uark-cviu.github.io/Type-to-Track/static/images/teaser_tao.png" alt="Type-to-Track: Retrieve Any Object
                                        via Prompt-based Tracking">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Type-to-Track: Retrieve Any Object via Prompt-based Tracking</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">One of the recent trends in vision problems is to use natural language captions to describe the objects of interest. This approach can overcome some limitations of traditional methods that rely on bounding boxes or category annotations. This paper introduces a novel paradigm for Multiple Object Tracking called Type-to-Track, which allows users to track objects in videos by typing natural language descriptions. We present a new dataset for that Grounded Multiple Object Tracking task, called GroOT, that contains videos with various types of objects and their corresponding textual captions describing their appearance and action in detail. Additionally, we introduce two new evaluation protocols and formulate evaluation metrics specifically for this task. We develop a new efficient method that models a transformer-based eMbed-ENcoDE-extRact framework (MENDER) using the third-order tensor decomposition. The experiments in five scenarios show that our MENDER approach outperforms another two-stage design in terms of accuracy and efficiency, up to 14.7% accuracy and 4× speed faster.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://uark-cviu.github.io/Type-to-Track/"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="https://uark-cviu.github.io/projects/quantum/img/quantumml/qnn_2.png" alt="Quantum Machine Learning and Autonomous 2D Crystals Identification">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Quantum Machine Learning and Autonomous 2D Crystals Identification</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">Classical neural network algorithms are computationally expensive. For example, in image classification, representing an image pixel by pixel using classical information requires an enormous amount of computational memory resources. Hence, exploring methods to represent images in a different paradigm of information is important. We proposed a parameter encoding scheme for defining and training neural networks in quantum information based on time evolution of quantum spaces.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://uark-cviu.github.io/projects/quantum/1_quantumml.html"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="https://campusdata.uark.edu/resources/images/articles/2023-10-30_09-36-47-PM_66758.jpg" alt="Researchers Receive NSF Funding to Continue Building a Smarter Insect Trap">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Researchers Receive NSF Funding to Continue Building a Smarter Insect Trap</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">Ashley Dowling, a researcher in the U of A System Division of Agriculture and professor of entomology and plant pathology, and Khoa Luu, an assistant professor of computer science and computer engineering, are leading development of the smarter insect trap.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://news.uark.edu/articles/66758/researchers-receive-nsf-funding-to-continue-building-a-smarter-insect-trap"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="https://campusdata.uark.edu/resources/images/articles/2023-08-25_04-31-20-PM_64968.jpg" alt="Graduate Students Take Third Place in MIT's Algonauts Project 2023 Challenge">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Graduate Students Take Third Place in MIT's Algonauts Project 2023 Challenge</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">Xuan Bac Nguyen, a Ph.D. candidate in the Department of Electrical Engineering and Computer Science, and his team placed third in the MIT Vision Brain Challenge, Algonauts Project 2023. The competition featuring more than 100 research teams around the world judges how successfully computational AI models predict brain responses to visual stimuli of natural scenes.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://news.uark.edu/articles/64968/graduate-students-take-third-place-in-mit-s-algonauts-project-2023-challenge"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="https://campusdata.uark.edu/resources/images/articles/2023-05-17_05-56-06-PM_64422.jpg" alt="Advanced Computer Vision">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Technology Ventures Inventor Spotlight: Khoa Luu</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">Recently Dr. Luu has been working on the problem that manually managing insects seems impossible as the size of a farm gets larger. Therefore, the ability to automatically detect and identify insects is a primary demand in the area of crop management. Despite the many advances in precision agriculture, this is one area still largely reliant on manual labor. A primary objective in this area is the ability to identify and count insect species in real-time.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://news.uark.edu/articles/64422/technology-ventures-inventor-spotlight-khoa-luu"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="./assets/img/publications/grid/houston.png" alt="Advanced Computer Vision">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Advanced Computer Vision and Deep
                                        Learning with Limited Data Approaches to Human
                                        Behavior Analysis and Scene Understanding in
                                        Open World</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="docs/houston.pdf"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="./assets/img/publications/grid/public-health-and-tech-speaker.png" alt="public-health-and-tech-speaker">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Advanced Artificial Intelligence and Deep Learning with Limited Data Approaches to Human Behavior Analysis and Health-Care Applications</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="docs/CPHT_KLuu.pdf"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="./assets/img/publications/grid/15290993697098387075.jpeg" alt="FutureFarming">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Short Takes: Caught on Camera: Insects Edition</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">University of Arkansas researchers have developed a prototype of an insect trap that can help farmers monitor and identify potential pests more efficiently in order to protect valuable crops. The trap, developed by researchers Ashley Dowling and Khoa Luu, captures footage of insects, uses artificial intelligence to identify them and sends real-time data back to the farmers. It also eliminates the need for manual monitoring, allowing farmers to make decisions on the fly and take the appropriate measures to counteract potential damage.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://www.youtube.com/watch?v=fwIAGTgrixs"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="https://honorsblog.uark.edu/files/2022/10/GrantPhoto-300x170-1.jpg" alt="FutureFarming">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Training AI to Detect Crop Pests</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">Pierce Helton is an Honors student studying Computer Science. This summer, he worked as a research assistant in the department’s Computer Vision and Image Understanding Lab. Here, he had an opportunity to broaden his understanding of machine learning and contribute to department research. Pierce plans to work in the industry and potentially pursue a M.S. in Computer Science after earning his B.S.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://honorsblog.uark.edu/training-ai-to-detect-crop-pests/"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="./assets/img/publications/grid/autism.png" alt="FutureFarming">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Researchers using artificial intelligence to assist with early detection of autism spectrum disorder</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">Faculty in food science and computer science/computer engineering are collaborating to develop machine learning that can assist in the detection of autism spectrum disorder.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://www.eurekalert.org/news-releases/962494"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="https://campusdata.uark.edu/resources/images/articles/PMUA_Logo-web.jpg" alt="FutureFarming">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">MonArk NSF Quantum Foundry Established With $20 Million Grant</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">With a $20 million grant from the National Science Foundation, the U of A and Montana State University will establish the MonArk NSF Quantum Foundry to accelerate the development of quantum materials and devices.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://news.uark.edu/articles/57527/monark-nsf-quantum-foundry-established-with-20-million-grant"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="https://campusdata.uark.edu/resources/images/articles/2020-06-23_02-35-32-PMCIF_1.jpg" alt="FutureFarming">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">Chancellor's Innovation and Collaboration Fund Awards 10 Faculty Research Projects</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">In a continuous effort to promote research activity, ten faculty research projects have been awarded grants from the Chancellor's Innovation and Collaboration Fund.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://news.uark.edu/articles/54173/chancellor-s-innovation-and-collaboration-fund-awards-10-faculty-research-projects"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1">
                                    <video controls width="100%"><source src="https://images.fastcompany.net/image/upload/w_1250,ar_16:9,c_fill,g_auto,f_webm,q_70/wp-cms/uploads/2019/03/p-2-Zuckerberg.gif" type="video/webm"></video>
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">This new AI tool ages faces in videos with creepy accuracy</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">A new machine learning paper shows how AI can take footage of someone and duplicate the video with the subject looking an age the researchers specify. The team behind the paper, from the University of Arkansas, Clemson University, Carnegie Mellon University, and Concordia University in Canada, claim that this is one of the first methods to use AI to tackle aging in videos.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://www.fastcompany.com/90314606/this-new-ai-tool-makes-creepily-realistic-videos-of-faces-in-the-future"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="https://wordpressua.uark.edu/vision/files/2018/09/Screen-Shot-2018-09-22-at-3.33.39-AM-1n8box2-768x300.png" alt="FutureFarming">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">ECCV 2018 - 2nd Unconstrained Face Detection and Open Set Recognition Challenge</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">We are the Winner #1 in both two tracks: Face Detection and Face Recognition.
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="https://vast.uccs.edu/Opensetface/"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div class="sp-line-80"></div>
                            <div class="row">
                                <div class="col-md-4 ol-hover hover-1"><img
                                        src="https://wordpressua.uark.edu/vision/files/2018/09/au-1p2wryo-768x366.jpg" alt="FutureFarming">
                                </div>
                                <div class="col-md-8">
                                    <h4 class="m-bottom-30">EmotioNet Challenge 2018</h4>
                                    <div class="dl-horizontal text-justify tight m-bottom-30">
                                        <div class="details">We are the 3rd in Track #2!
                                            <br><br><span style="font-family:Source Code Pro"><a class="link-with-icon"
                                                    href="http://cbcsl.ece.ohio-state.edu/EmotionNetChallenge/index.html#enc-2018"><i
                                                        class="fa fa-link"></i>Link</a></span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </section>
                </section>
                <div class="clearfix"></div>
            </section>
        </section>
        <footer id="footer" class="dark-wrapper">
            <div id="footer-bar">
                <div class="container">
                    <div class="row tb-vcenter-wrapper bottom-bar">
                        <div class="col-sm-8 vcenter">
                            <ul class="footer-menu">
                                <li><a href="./index.html">Home</a></li>
                                <li><a href="./publication.html">Publication</a></li>
                                <li><a href="https://github.com/uark-cviu">Data & Code</a></li>
                                <li><a href="./news.html"><b>News</b></a></li>
                                <li><a href="./people.html">People</a></li>
                                <li><a href="./contact.html">Contact</a></li>
                            </ul>
                            <div class="sp-blank-10"></div>
                            <div class="inline-wrapper">
                                <div class="copyright"><i class="fa fa-copyright"></i> CVIU Lab
                                    <script>document.write(new Date().getFullYear())</script>.
                                </div>
                            </div>
                        </div>
                        <div class="col-sm-4 vcenter footer-socials">
                            <ul class="social-icons border-circle hover-tb-theme text-right-sm">
                                <li><a href="mailto:khoaluu@uark.edu"><i class="fa fa-envelope"></i></a></li>
                                <li><a href="tel:+14126085708"><i class="fa fa-phone"></i></a></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </footer>
    </div>
    <script src="./assets/js/vendors/vendors.js"></script>
    <script src="./assets/js/custom.js"></script>
</body>

</html>