
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>EAGLE</title>
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="static/images/UA_Logo.png">
  
  <!-- Fonts and Icons -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  
  <!-- CSS Libraries -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  
  <!-- Google Analytics -->
  <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'G-825ET94Y3E');
  </script>
  
  <!-- JavaScript Libraries -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
  
<body>
  <section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">EAGLE <img src="static/images/eagle.png" alt="Icon" style="height: 52px;">: Efficient Adaptive Geometry-based Learning in Cross-view Understanding</h1>
                    <!-- <h1 class="title is-1 publication-title">EAGLE ðŸ¦…: Efficient Adaptive Geometry-based Learning in Cross-view Understanding</h1> -->
                    <div class="is-size-5 publication-authors">
                      <!-- Paper authors -->
                      <span class="author-block">
                      <a href="" target="_blank">Thanh-Dat Truong<sup>1</sup></a>,</span>
                      <a href="" target="_blank">Utsav Prabhu<sup>2</sup></a>,</span>
                      <a href="" target="_blank">Dongyi Wang<sup>3</sup></a>,</span><br>
                      <a href="" target="_blank">Bhiksha Raj<sup>4,5</sup></a>,</span>
                      <a href="" target="_blank">Susan Gauch<sup>6</sup></a>,</span>
                      <a href="" target="_blank">Jeyamkondan Subbiah<sup>7</sup></a>,</span>
                      <a href="" target="_blank">Khoa Luu<sup>1</sup></a></span>
                      </span>
                  </div>
                  <div class="is-size-5 publication-authors">
                      <span class="author-block">
                        <sup>1</sup>CVIU Lab, University of Arkansas&nbsp;&nbsp;&nbsp;&nbsp;
                        <sup>2</sup>Google DeepMind&nbsp;&nbsp;&nbsp;&nbsp;
                        <sup>3</sup>Dep. of BAEG, University of Arkansas&nbsp;&nbsp;&nbsp;&nbsp;
                        <sup>4</sup>Carnegie Mellon University&nbsp;&nbsp;&nbsp;&nbsp;
                        <sup>5</sup>Mohammed bin Zayed University of AI&nbsp;&nbsp;&nbsp;&nbsp;
                        <br>
                        <sup>6</sup>Dep. of EECS, University of Arkansas&nbsp;&nbsp;&nbsp;&nbsp;
                        <sup>7</sup>Dep. of FDSC, University of Arkansas&nbsp;&nbsp;&nbsp;&nbsp;
                      </span>
                      <br>
                  </div>
                  <p style="color:#000; font-weight:bold; font-size:1.5em;" class="text-center">ðŸŽ‰ <strong>Accepted to NeurIPS 2024</strong> ðŸŽ‰</p>
                    <!-- Publication Links -->
                    <div class="publication-links">
                        <!-- ArXiv abstract Link -->
                        <span class="link-block">
                            <a href="https://arxiv.org/abs/2406.01429" target="_blank" class="external-link button is-normal is-rounded is-dark">
                                <span class="icon">
                                    <i class="ai ai-arxiv"></i>
                                </span>
                                <span>arXiv</span>
                            </a>
                        </span>
                        
                    </div>
                    <!-- Video Container -->
                    <div class="video-container">
                      <video autoplay muted loop playsinline>
                          <source src="static/videos/eagle-teaser.mp4" type="video/mp4">
                      </video>
                      
                  </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Paper motivation -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Highlights</h2>
        <div class="content has-text-justified">
          <p>
            <ul>
              <li>We introduce a novel Efficient Adaptive Geometry-based Learning (EAGLE) to Unsupervised Cross-view Adaptation that can adaptively learn and improve the performance of semantic segmentation models across camera viewpoints.</li>
              <li>We introduce a new Geodesic Flow-based Metric to measure the structural changes across views via their manifold structures.</li>
              <li>We introduce a new view-condition prompting to further improve the prompting mechanism of the open-vocab segmentation network in cross-view adaptation learning.</li>
            </ul>
            <figure>
              <!-- <figcaption class="content has-text-left" style="word-break:normal"> Comparisons with Domain Adaptation Approaches. -->
              <img src="static/images/Cross-View-Framework-V7.jpg" alt="fail" width="100%">
            </figure>
          </p>
        </div>
      </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
            <p>
              Unsupervised Domain Adaptation has been an efficient approach to transferring the semantic segmentation model across
              data distributions. Meanwhile, the recent Open-vocabulary Semantic Scene understanding based on large-scale vision
              language models is effective in open-set settings because it can learn diverse concepts and categories. However, these
              prior methods fail to generalize across different camera views due to the lack of cross-view geometric modeling. At
              present, there are limited studies analyzing cross-view learning. To address this problem, we introduce a novel
              Unsupervised Cross-view Adaptation Learning approach to modeling the geometric structural change across views in
              Semantic Scene Understanding. First, we introduce a novel Cross-view Geometric Constraint on Unpaired Data to model
              structural changes in images and segmentation masks across cameras. Second, we present a new Geodesic Flow-based
              Correlation Metric to efficiently measure the geometric structural changes across camera views. Third, we introduce a
              novel view-condition prompting mechanism to enhance the view-information modeling of the open-vocabulary segmentation
              network in cross-view adaptation learning. The experiments on different cross-view adaptation benchmarks have shown the
              effectiveness of our approach in cross-view modeling, demonstrating that we achieve State-of-the-Art (SOTA) performance
              compared to prior unsupervised domain adaptation and open-vocabulary semantic segmentation methods.
            </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Qualitative Results</h2>

        <figure>
          <figcaption class="content has-text-left" style="word-break:normal">The Qualitative Results of Cross-View Adaptation (Without Prompt).
          <img src="static/images/uda-compare-crovia-proda.jpg" alt="fail" width="100%">
        </figure>

        <figure>
          <figcaption class="content has-text-left" style="word-break:normal">The Qualitative Results of Cross-View Adaptation (With Prompt).
          <img src="static/images/uda-eagle-prompt.jpg" alt="fail" width="100%">
        </figure>

        <figure>
          <figcaption class="content has-text-left" style="word-break:normal">Results of Segmenting Cars, Trees, Persons. (A) Input, (B) FreeSeg, and (C) EAGLE.
          <img src="static/images/ResultCrossView-V3.jpg" alt="fail" width="100%">
        </figure>

      </div>
    </div>
  </div>
</section>



<section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
        <h2 class="title is-3">Experimental Results</h2>

        <div class="content has-text-left is-size-5">
        <center>
        <strong>Unsupervised Domain Adaptation</strong>
        </center>
        </div>
        
        <figure>
            <!-- <figcaption class="content has-text-left" style="word-break:normal"> Comparisons with Domain Adaptation Approaches. -->
            <img src="static/images/UDA.png" alt="fail" width="100%">
        </figure>

        <br>

        <div class="content has-text-left is-size-5">
          <center>
          <strong>Open-vocab Semantic Segmentation</strong>
          </center>
        </div>

        <figure>
          <!-- <figcaption class="content has-text-left" style="word-break:normal"> Comparisons with Domain Adaptation Approaches. -->
          <img src="static/images/open-vocab.png" alt="fail" width="100%">
        </figure>
        
        <br>

        <div class="content has-text-left is-size-5">
          <center>
          <strong>Open-vocab Semantic Segmentation on Unseen Classes</strong>
          </center>
        </div>

        <figure>
          <!-- <figcaption class="content has-text-left" style="word-break:normal"> Comparisons with Domain Adaptation Approaches. -->
          <img src="static/images/open-vocab-unseen.png" alt="fail" width="100%">
        </figure>
        
        <br>
        <div class="content has-text-left is-size-5">
          <center>
          <strong>Real-to-Real Cross-view Adaptation Setting</strong>
          </center>
        </div>

        <figure>
          <!-- <figcaption class="content has-text-left" style="word-break:normal"> Comparisons with Domain Adaptation Approaches. -->
          <img src="static/images/real2real.png" alt="fail" width="100%">
        </figure>
        

      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">BibTex</h2>
    <pre><code>@inproceedings{truong2024eagle,
      title={EAGLE: Efficient Adaptive Geometry-based Learning in Cross-view Understanding},
      author={Thanh-Dat Truong and Utsav Prabhu and Dongyi Wang and Bhiksha Raj and Susan Gauch and Jeyamkondan Subbiah and Khoa Luu},
      booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
      year={2024}
    }
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <center>
          <p>
            This project template was adopted from <a href="https://nerfies.github.io" target="_blank">Nerfies</a>.
          </p>
        </center>

        </div>
      </div>
    </div>
  </div>
</footer>
  <!-- Initialize Slick Carousel -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
        let currentVideoIndex = 0;
        const videos = document.querySelectorAll('.videos video');
        const totalVideos = videos.length;

        document.getElementById('prevBtn').addEventListener('click', function() {
            changeVideo(-1);
        });

        document.getElementById('nextBtn').addEventListener('click', function() {
            changeVideo(1);
        });

        document.querySelectorAll('.img-zoom').forEach(img => {
            img.addEventListener('click', function() {
                this.classList.toggle('active');
            });
        });

        function changeVideo(direction) {
            videos[currentVideoIndex].style.display = 'none';
            currentVideoIndex = (currentVideoIndex + direction + totalVideos) % totalVideos;
            videos[currentVideoIndex].style.display = 'block';
        }

        function openModal(img) {
            var modal = document.getElementById("myModal");
            var modalImg = document.getElementById("img01");
            modal.style.display = "block";
            modalImg.src = img.src;
        }

        var span = document.getElementsByClassName("close")[0];
        if (span) {
            span.onclick = function() { 
                var modal = document.getElementById("myModal");
                modal.style.display = "none";
            }
        }
    });
  </script>
</body>
</html>
